{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "later-temple",
   "metadata": {},
   "source": [
    "# Part 1: Read in CSV files and Make Dataframes\n",
    "1. Get all csv files using glob.glob to path\n",
    "2. Read CSV files into dataframes\n",
    "3. Collect data on aggregate mean, min, and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-fleet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "csvs = glob.glob(\"C:/Users/fanj4/OneDrive - Children's Hospital of Philadelphia/Documents/Video_Data/*.csv\")\n",
    "print(csvs)\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-premiere",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_min = []\n",
    "agg_max = []\n",
    "agg_mean = []\n",
    "min_fx = []\n",
    "max_fx = []\n",
    "mean_fx = []\n",
    "for csv in csvs:\n",
    "    df = pd.read_csv(csv, index_col=None, header=0)\n",
    "    c = df['confidence']\n",
    "    print(df['confidence'].min())\n",
    "    agg_min.append(df['confidence'].min())\n",
    "    agg_max.append(df['confidence'].max())\n",
    "    agg_mean.append(df['confidence'].mean())\n",
    "    df = df.drop(df.index [ [0, 90] ])\n",
    "    df = df.drop(c.index [ [len(c.index)-90, len(c.index)-1] ])\n",
    "    min_fx.append(df['confidence'].min())\n",
    "    max_fx.append(df['confidence'].max())\n",
    "    mean_fx.append(df['confidence'].mean())\n",
    "    #data.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-silence",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(agg_min, bins = 20, edgecolor = 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-april",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(agg_max, bins = 20, edgecolor = 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-combat",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(agg_mean, bins = 20, edgecolor = 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(min_fx, bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(max_fx, bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-immune",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mean_fx, bins = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-damages",
   "metadata": {},
   "source": [
    "# Part 2: Data Cleaning - Identify and Remove Bad Frames\n",
    "\n",
    "- Majority of low confidence frames were when subject were looking off to the side and quickly moving their head back to center or shaking their head side to side such that only side profile is visable.\n",
    "- We defined \"good data\" as frames with confidence greater than or equal to 0.5.\n",
    "- Because of adjustments and movements at the beginning of videos, many frames at the beginning of the recording are low confidence. Therefore, we chose to cut out the first 10 seconds (300 frames) of each video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-chance",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "bad_data_frames = []\n",
    "for csv in csvs:\n",
    "    # Total Number of Videos, prevents errors\n",
    "    if t > 246:\n",
    "        break\n",
    "    t+=1\n",
    "    df1 = pd.read_csv(csv, index_col=None, header = 0)\n",
    "    df = df1.tail(-300)\n",
    "    file_name = csv.split('\\\\')\n",
    "    ID = file_name[1].split('.csv')\n",
    "    print(ID[0])\n",
    "    df.plot(x='timestamp', y='confidence')\n",
    "    good_data = df[df.confidence >= 0.5]\n",
    "    bad_data = df[df.confidence < 0.5]\n",
    "    print(list(bad_data[\"timestamp\"]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-mambo",
   "metadata": {},
   "source": [
    "# Part 3: Generate 13 Variables\n",
    "1. For each file in 'csvs'\n",
    "    a. Run pd.read_csv to get each column in csv\n",
    "    b. Take out bad frames with confidence below 0.6 \n",
    "    c. Generate 13 variables based on 3 columns: 'pose_Rx', 'pose_Ry', 'pose_Rz'\n",
    "2. Notes on what each variable is:\n",
    "- *Note: each variable takes the individual values of the pitch, yaw, and roll\n",
    "- v1x, v1y, v1z = Square root of average square values of each frame\n",
    "- v2x, v2y, v2z = Sqrt of average difference of consecutive frames squared\n",
    "- v3x, v3y, v3z = maximum value - minimum value across all frames\n",
    "- v4x, v4y, v4z = Sum of the positive difference between consecutive frames divided by frames per second\n",
    "- v13 = Average of slant from all three directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-lunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =[]\n",
    "vdata = []\n",
    "print(len(csvs))\n",
    "t = 0\n",
    "for proj in csvs:\n",
    "\n",
    "#     print(proj)\n",
    "    file_name = proj.split('\\\\')\n",
    "    ID = file_name[1].split('.csv')\n",
    "#     print(ID[0])\n",
    "                    \n",
    "    t+=1\n",
    "    df = pd.read_csv(proj, index_col=None, header = 0)\n",
    "    \n",
    "\n",
    "    good_data = df[df['confidence'] >= 0.6]\n",
    "    print(good_data)\n",
    "    good_data.nsmallest(n = math.floor(50), columns = ['confidence'])\n",
    "\n",
    "    dfRx = good_data['pose_Rx']\n",
    "    dfRy = good_data['pose_Ry']\n",
    "    dfRz = good_data['pose_Rz']\n",
    "    frames = good_data['frame']\n",
    "    if (dfRx.size == 0 or dfRy.size == 0 or dfRz.size == 0):\n",
    "        continue\n",
    "    \n",
    "    v1x = math.sqrt(dfRx.pow(2).sum()/dfRx.size)\n",
    "    v2x = 0.0\n",
    "    v4x = 0.0\n",
    "    for i in range(len(dfRx)):\n",
    "        if (i == 1):\n",
    "            continue\n",
    "        if pd.isna(dfRx.iloc[i]):\n",
    "            dfRx.iloc[i] = 0\n",
    "        if pd.isna(dfRx.iloc[i-1]):\n",
    "            dfRx.iloc[i-1] = 0\n",
    "        if frames.iloc[i]-frames.iloc[i-1] > 10:\n",
    "            continue\n",
    "        v2x += (float(dfRx.iloc[i]) - float(dfRx.iloc[i-1])) ** 2\n",
    "        v4x += abs(float(dfRx.iloc[i]) - float(dfRx.iloc[i-1]))\n",
    "    v2x = math.sqrt(v2x/dfRx.size)\n",
    "    v3x = dfRx.max() - dfRx.min()\n",
    "    v4x = 1800*v4x/dfRx.size\n",
    "    \n",
    "    v1y = math.sqrt(dfRy.pow(2).sum()/dfRy.size)\n",
    "    v2y = 0.0\n",
    "    v4y = 0.0\n",
    "    for i in range(len(dfRy)):\n",
    "        if (i == 1):\n",
    "            continue\n",
    "        if pd.isna(dfRy.iloc[i]):\n",
    "            dfRy.iloc[i] = 0\n",
    "        if pd.isna(dfRy.iloc[i-1]):\n",
    "            dfRy.iloc[i-1] = 0\n",
    "        if frames.iloc[i]-frames.iloc[i-1] > 10:\n",
    "            continue\n",
    "        v2y += (float(dfRy.iloc[i]) - float(dfRy.iloc[i-1])) ** 2\n",
    "        v4y += abs(float(dfRy.iloc[i]) - float(dfRy.iloc[i-1]))\n",
    "    v2y = math.sqrt(v2y/dfRy.size)\n",
    "    v3y = dfRy.max() - dfRy.min()\n",
    "    v4y = 1800*v4y/dfRy.size\n",
    "    \n",
    "    v1z = math.sqrt(dfRz.pow(2).sum()/dfRz.size)\n",
    "    v2z = 0.0\n",
    "    v4z = 0.0\n",
    "    for i in range(len(dfRz)):\n",
    "        if (i == 1):\n",
    "            continue\n",
    "        if pd.isna(dfRz.iloc[i]):\n",
    "            dfRz.iloc[i] = 0\n",
    "        if pd.isna(dfRz.iloc[i-1]):\n",
    "            dfRz.iloc[i-1] = 0\n",
    "        if frames.iloc[i]-frames.iloc[i-1] > 10:\n",
    "            continue\n",
    "        v2z += (float(dfRz.iloc[i]) - float(dfRz.iloc[i-1])) ** 2\n",
    "        v4z += abs(float(dfRz.iloc[i]) - float(dfRz.iloc[i-1]))\n",
    "    v2z = math.sqrt(v2z/dfRz.size)\n",
    "    v3z = dfRz.max() - dfRz.min()\n",
    "    v4z = 1800*v4z/dfRz.size\n",
    "    \n",
    "    v13 = 0.0\n",
    "    for i in range(len(dfRx)):\n",
    "        if pd.isna(dfRz.iloc[i]):\n",
    "            dfRz.iloc[i] = 0\n",
    "        if pd.isna(dfRy.iloc[i]):\n",
    "            dfRy.iloc[i] = 0\n",
    "        if pd.isna(dfRx.iloc[i]):\n",
    "            dfRx.iloc[i] = 0\n",
    "        v13 += math.sqrt(float(dfRx.iloc[i])**2+float(dfRy.iloc[i])**2+float(dfRz.iloc[i])**2)\n",
    "    v13 /= dfRx.size\n",
    "    \n",
    "    variables = {'ID':  ID[0], 'v1_x':v1x, 'v2_x':v2x, 'v3_x':v3x, 'v4_x':v4x,'v1_y':v1y, 'v2_y':v2y, 'v3_y':v3y, 'v4_y':v4y, 'v1_z':v1z, 'v2_z':v2z, 'v3_z':v3z, 'v4_z':v4z, 'v13':v13}\n",
    "    vdata.append(variables)\n",
    "    \n",
    "    df1 = pd.DataFrame(good_data, columns=['frame'])\n",
    "    df2 = pd.DataFrame(good_data, columns=['confidence'])\n",
    "    data.append(good_data)\n",
    "#     print(df)\n",
    "print(data)#Check Output 1\n",
    "# df2 = pd.concat(data, ignore_index=True)\n",
    "# Are face IDs always 0?\n",
    "# df2#check output 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-bonus",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-participant",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata_df = pd.DataFrame(vdata)\n",
    "vdata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-publicity",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata_df.to_csv(\"C:/Users/fanj4/OneDrive - Children's Hospital of Philadelphia/Documents/Video_Data/VideoDataUpdated_Version2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
